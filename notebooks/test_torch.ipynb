{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu113\n",
      "11.3\n",
      "0.11.1+cu113\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.hub\n",
    "\n",
    "import torchvision\n",
    "import torchvision.utils\n",
    "\n",
    "from data import dataset as data\n",
    "import data.utils as data_utils\n",
    "import attack_construction.attack_methods as attack_methods\n",
    "import attack_construction.metrics as metrics\n",
    "import attack_construction.utils as attack_utils\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda_version)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "model = model.float().to(device)\n",
    "\n",
    "dataset = data.AdversarialDataset() # todo: use resize to pull picture in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = attack_utils.load_tensor(\"patch - new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[5]\n",
    "\n",
    "patch = torch.rand(3, 1000, 4)\n",
    "\n",
    "image_before, image_after = attack_utils.get_patch_test(patch, image, label, model, device, None, 0.5)\n",
    "\n",
    "cv2.imshow(\"patch\", cv2.cvtColor(np.concatenate((image_before/255, image_after/255), axis = 1), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "key = cv2.waitKey(0)\n",
    "if key & 0xFF == ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Степан\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "image, label = dataset[5]\n",
    "pred_label = model([data_utils.image_to_tensor(image)])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[103.3200, 133.4500, 231.0300, 421.8900],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9512, 0.8752, 0.8034, 0.7582, 0.7398, 0.6379, 0.6187, 0.5611, 0.5536,\n",
      "        0.5497, 0.4910, 0.4495, 0.4459, 0.4458, 0.4436, 0.4421, 0.3846, 0.3770,\n",
      "        0.3603, 0.3546, 0.3243, 0.2736, 0.2644, 0.2584, 0.2577, 0.2550, 0.2480,\n",
      "        0.2450, 0.2309, 0.2288, 0.2191, 0.2105, 0.2077, 0.1965, 0.1937, 0.1935,\n",
      "        0.1928, 0.1863, 0.1857, 0.1797, 0.1781, 0.1781, 0.1779, 0.1734, 0.1702,\n",
      "        0.1660, 0.1554, 0.1507, 0.1502, 0.1493, 0.1489, 0.1482, 0.1481, 0.1467,\n",
      "        0.1444, 0.1427, 0.1423, 0.1410, 0.1408, 0.1390, 0.1367, 0.1342, 0.1342,\n",
      "        0.1340, 0.1337, 0.1325, 0.1320, 0.1291, 0.1286, 0.1282, 0.1281, 0.1270,\n",
      "        0.1264, 0.1264, 0.1263, 0.1261, 0.1259, 0.1223, 0.1211, 0.1208, 0.1208,\n",
      "        0.1201, 0.1183, 0.1178, 0.1164, 0.1159, 0.1157, 0.1149, 0.1141, 0.1134,\n",
      "        0.1133, 0.1127, 0.1125, 0.1123, 0.1117, 0.1103, 0.1099, 0.1094, 0.1078,\n",
      "        0.1067, 0.1067, 0.1054, 0.1053, 0.1051, 0.1045, 0.1043, 0.1031, 0.1029,\n",
      "        0.1028, 0.1019, 0.1016, 0.1015, 0.1011, 0.1006, 0.0989, 0.0965, 0.0962,\n",
      "        0.0948, 0.0943, 0.0934, 0.0925, 0.0915, 0.0895, 0.0894, 0.0887, 0.0883,\n",
      "        0.0878, 0.0872, 0.0865, 0.0863, 0.0858, 0.0856, 0.0855, 0.0852, 0.0851,\n",
      "        0.0846, 0.0830, 0.0824, 0.0823, 0.0822, 0.0819, 0.0819, 0.0814, 0.0813,\n",
      "        0.0813, 0.0809, 0.0806, 0.0802, 0.0802, 0.0795, 0.0794, 0.0794, 0.0791,\n",
      "        0.0785, 0.0772, 0.0767, 0.0762, 0.0761, 0.0759, 0.0752, 0.0746, 0.0745,\n",
      "        0.0744, 0.0743, 0.0741, 0.0740, 0.0738, 0.0737, 0.0735, 0.0733, 0.0730,\n",
      "        0.0723, 0.0722, 0.0720, 0.0719, 0.0715, 0.0709, 0.0701, 0.0700, 0.0699,\n",
      "        0.0696, 0.0691, 0.0688, 0.0687, 0.0687, 0.0686, 0.0683, 0.0680, 0.0677,\n",
      "        0.0673, 0.0672, 0.0664, 0.0661, 0.0659, 0.0652, 0.0650, 0.0648, 0.0647,\n",
      "        0.0647, 0.0642, 0.0640, 0.0639, 0.0627, 0.0611, 0.0606, 0.0594, 0.0582,\n",
      "        0.0579, 0.0549, 0.0545, 0.0545, 0.0534, 0.0531, 0.0530, 0.0527, 0.0527,\n",
      "        0.0519, 0.0505, 0.0502], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pred_label['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9078], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.intersection_over_union(pred_label['boxes'][0].detach(), label[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\codeop.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, source, filename, symbol)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mcodeob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcodeob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mco_flags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiler_flag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiler_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = data.AdversarialDataset((800,300))\n",
    "dataset_val = data.AdversarialDataset((640,640), '../../val2017/val2017', '../../annotations_trainval2017/annotations/instances_train2017.json')\n",
    "train_loader  = torch.utils.data.DataLoader(dataset=dataset, batch_size=3, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=torch.utils.data.Subset(dataset_val,5), batch_size=3, shuffle=False)\n",
    "def loss_function(predict, patch, device):\n",
    "        return metrics.general_objectness(predict, device) + 0 * metrics.total_variation(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "362d69d123881ce57a887ab45a3f9acb2a40ab5f881fb7cd46244a03df42c740"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
